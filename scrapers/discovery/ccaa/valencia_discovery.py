"""
Auto-discovery de URLs del DOGV (Diari Oficial de la Generalitat Valenciana)
Busca autom√°ticamente las resoluciones de festivos locales desde la p√°gina oficial
"""

from typing import Dict, Optional
import requests
from bs4 import BeautifulSoup
import re


def auto_discover_valencia(year: int) -> Optional[str]:
    """
    Intenta descubrir autom√°ticamente la URL del DOGV con festivos locales.
    
    Estrategia:
    1. Buscar en la p√°gina oficial: https://ceice.gva.es/es/web/dg-trabajo/calendario-laboral
    2. Encontrar el enlace a la resoluci√≥n de festivos locales para el a√±o
    3. Seguir el enlace al DOGV
    4. Extraer el PDF y validar
    
    Args:
        year: A√±o para el cual buscar festivos
        
    Returns:
        URL del DOGV si se encuentra, None si no
    """
    print(f"üîç Buscando URL del DOGV para festivos locales de Valencia {year}...")
    
    url_oficial = "https://ceice.gva.es/es/web/dg-trabajo/calendario-laboral"
    
    try:
        r = requests.get(url_oficial, timeout=15)
        if r.status_code != 200:
            print(f"   ‚ö†Ô∏è  No se pudo acceder a {url_oficial}")
            return None
        
        soup = BeautifulSoup(r.text, 'html.parser')
        
        # Buscar enlaces que contengan el a√±o y "resoluci√≥n" o "fiestas locales"
        enlaces = soup.find_all('a', href=True)
        
        for enlace in enlaces:
            href = enlace['href']
            texto = enlace.text.strip()
            
            # Filtrar: debe contener el a√±o y "resoluci√≥n" + "fiestas locales"
            if str(year) in texto:
                if 'resoluci√≥n' in texto.lower() or 'resoluci√≥' in texto.lower():
                    if 'fiestas locales' in texto.lower() or 'festes locals' in texto.lower():
                        
                        # Construir URL completa
                        if href.startswith('http'):
                            url_resolucion = href
                        elif href.startswith('/'):
                            url_resolucion = f"https://ceice.gva.es{href}"
                        else:
                            # URL relativa
                            url_resolucion = f"https://ceice.gva.es/es/web/dg-trabajo/{href}"
                        
                        print(f"   üîç Probando: {texto[:80]}...")
                        print(f"   üìç URL resoluci√≥n: {url_resolucion}")
                        
                        # Seguir el enlace
                        url_pdf = _extraer_url_pdf_desde_enlace(url_resolucion, year)
                        if url_pdf:
                            print(f"   ‚úÖ URL encontrada: {url_pdf}")
                            return url_pdf
        
        print(f"   ‚ùå No se encontr√≥ URL autom√°ticamente para {year}")
        return None
        
    except Exception as e:
        print(f"   ‚ö†Ô∏è  Error: {e}")
        return None


def _extraer_url_pdf_desde_enlace(url_enlace: str, year: int) -> Optional[str]:
    """
    Sigue un enlace y extrae la URL del PDF.
    Puede ser que el enlace apunte directamente al DOGV o necesite redirecciones.
    
    Args:
        url_enlace: URL del enlace a seguir
        year: A√±o para validar
        
    Returns:
        URL del PDF si se encuentra y valida, None si no
    """
    try:
        # Seguir el enlace (permitir redirecciones)
        r = requests.get(url_enlace, timeout=15, allow_redirects=True)
        if r.status_code != 200:
            return None
        
        # Si la URL final es del DOGV, buscar el PDF ah√≠
        if 'dogv.gva.es' in r.url:
            return _extraer_url_pdf_desde_dogv(r.url, year, r.text)
        else:
            # Si no, parsear la p√°gina actual buscando enlaces al DOGV
            soup = BeautifulSoup(r.text, 'html.parser')
            enlaces_dogv = soup.find_all('a', href=re.compile(r'dogv\.gva\.es', re.I))
            
            for enlace in enlaces_dogv:
                href = enlace['href']
                if href.startswith('http'):
                    url_dogv = href
                else:
                    url_dogv = f"https:{href}" if href.startswith('//') else f"https://dogv.gva.es{href}"
                
                print(f"      üîó Siguiendo enlace a DOGV: {url_dogv[:80]}...")
                
                # Intentar extraer PDF desde esa URL del DOGV
                url_pdf = _extraer_url_pdf_desde_dogv(url_dogv, year)
                if url_pdf:
                    return url_pdf
        
        return None
        
    except Exception as e:
        print(f"      ‚ö†Ô∏è  Error siguiendo enlace: {e}")
        return None


def _extraer_url_pdf_desde_dogv(url_dogv: str, year: int, contenido_html: str = None) -> Optional[str]:
    """
    Extrae la URL del PDF desde una p√°gina del DOGV.
    Prueba diferentes fechas de publicaci√≥n en nov-dic del a√±o anterior.
    
    Args:
        url_dogv: URL de la p√°gina del DOGV
        year: A√±o para validar
        contenido_html: HTML ya descargado (opcional)
        
    Returns:
        URL del PDF si se encuentra y valida, None si no
    """
    try:
        # Extraer signatura de la URL (ej: 2025/46326)
        match_signatura = re.search(r'signatura=([^&]+)', url_dogv)
        if not match_signatura:
            return None
        
        signatura = match_signatura.group(1)
        signatura_underscore = signatura.replace('/', '_')
        a√±o_publicacion = year - 1  # Generalmente se publica el a√±o anterior
        
        print(f"      üìã Signatura: {signatura}")
        print(f"      üîç Buscando PDF en {a√±o_publicacion}...")
        
        # Probar solo noviembre (mes m√°s com√∫n para festivos locales)
        # Luego diciembre, luego octubre
        meses_probar = [11, 12, 10]
        
        for mes in meses_probar:
            dias_mes = 31 if mes in [10, 12] else 30
            
            for dia in range(1, dias_mes + 1):
                # Probar primero espa√±ol, luego valenciano
                for idioma in ['es', 'va']:
                    url_pdf = f"https://dogv.gva.es/datos/{a√±o_publicacion}/{mes:02d}/{dia:02d}/pdf/{signatura_underscore}_{idioma}.pdf"
                    
                    # HEAD request para ver si existe
                    try:
                        r_pdf = requests.head(url_pdf, timeout=2)
                        if r_pdf.status_code == 200:
                            print(f"      ‚úÖ PDF encontrado: {a√±o_publicacion}-{mes:02d}-{dia:02d}")
                            
                            # Validar contenido r√°pido (solo verificar que es PDF v√°lido)
                            if _validar_pdf_valencia(url_pdf, year):
                                return url_pdf
                    except:
                        continue
        
        print(f"      ‚ùå No se encontr√≥ PDF para {signatura}")
        return None
        
    except Exception as e:
        print(f"      ‚ö†Ô∏è  Error: {e}")
        return None


def _validar_pdf_valencia(url_pdf: str, year: int) -> bool:
    """
    Valida que el PDF contenga festivos locales de Valencia.
    
    Validaci√≥n:
    - Debe contener al menos 2 de las 3 provincias
    - Debe contener m√∫ltiples municipios (>50 l√≠neas con formato MUNICIPIO:)
    - Debe mencionar el a√±o
    """
    try:
        import tempfile
        import os
        from pypdf import PdfReader
        
        r = requests.get(url_pdf, timeout=30)
        if r.status_code != 200:
            return False
        
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp:
            tmp.write(r.content)
            tmp_path = tmp.name
        
        try:
            reader = PdfReader(tmp_path)
            texto = ""
            # Extraer TODAS las p√°ginas (no solo las primeras 5)
            for page in reader.pages:
                texto += page.extract_text()
            
            # Validar provincias
            provincias_encontradas = sum([
                'ALICANTE' in texto,
                'CASTELL√ìN' in texto or 'CASTELL√ì' in texto,
                'VALENCIA' in texto or 'VAL√àNCIA' in texto
            ])
            
            if provincias_encontradas < 2:
                return False
            
            # Validar a√±o
            if str(year) not in texto:
                return False
            
            # Validar m√∫ltiples municipios (patr√≥n MUNICIPIO:)
            municipios = len(re.findall(r'^[A-Z√Å√â√ç√ì√ö√ë√ú\',\s]+:', texto, re.MULTILINE))
            
            if municipios < 50:  # Al menos 50 municipios
                return False
            
            print(f"      ‚úÖ PDF validado: {provincias_encontradas}/3 provincias, {municipios} municipios")
            return True
            
        finally:
            os.unlink(tmp_path)
            
    except Exception as e:
        print(f"      ‚ö†Ô∏è  Error validando PDF: {e}")
        return False


def get_cached_url(year: int, cache_file: str = 'config/valencia_urls_cache.json') -> Optional[str]:
    """Obtiene URL desde el cach√© si existe"""
    import json
    import os
    
    if not os.path.exists(cache_file):
        return None
    
    try:
        with open(cache_file, 'r') as f:
            cache = json.load(f)
        
        url = cache.get('locales', {}).get(str(year))
        if url:
            print(f"üì¶ URL cargada desde cach√©: {url}")
        return url
    except:
        return None


def save_to_cache(year: int, url: str, tipo: str = 'locales', cache_file: str = 'config/valencia_urls_cache.json'):
    """Guarda URL en el cach√©"""
    import json
    import os
    
    cache = {}
    if os.path.exists(cache_file):
        try:
            with open(cache_file, 'r') as f:
                cache = json.load(f)
        except:
            cache = {}
    
    if tipo not in cache:
        cache[tipo] = {}
    
    cache[tipo][str(year)] = url
    
    os.makedirs(os.path.dirname(cache_file), exist_ok=True)
    with open(cache_file, 'w') as f:
        json.dump(cache, f, indent=2)
    
    print(f"üíæ URL guardada en cach√©: {cache_file}")


if __name__ == "__main__":
    import sys
    
    year = int(sys.argv[1]) if len(sys.argv) > 1 else 2026
    
    print(f"{'='*80}")
    print(f"üîç AUTO-DISCOVERY: Valencia Locales {year}")
    print(f"{'='*80}\n")
    
    # Intentar desde cach√© primero
    url = get_cached_url(year)
    
    if not url:
        # Buscar autom√°ticamente
        url = auto_discover_valencia(year)
        
        if url:
            # Guardar en cach√©
            save_to_cache(year, url)
    
    if url:
        print(f"\n‚úÖ URL final: {url}")
    else:
        print(f"\n‚ùå No se pudo encontrar URL para {year}")