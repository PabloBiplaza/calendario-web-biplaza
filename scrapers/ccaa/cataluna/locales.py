"""
Catalu√±a Locales Scraper
Extrae festivos locales desde el DOGC (Diari Oficial de la Generalitat de Catalunya)
Parsea XML en formato Akoma Ntoso con HTML escapado
"""

from typing import List, Dict, Optional
import re
import requests
import xml.etree.ElementTree as ET
import html
from bs4 import BeautifulSoup
from scrapers.core.base_scraper import BaseScraper
import urllib3

# Deshabilitar advertencias SSL
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


class CatalunaLocalesScraper(BaseScraper):
    """Scraper para festivos locales de Catalu√±a"""
    
    CACHE_FILE = "config/cataluna_urls_cache.json"
    
    def __init__(self, year: int, municipio: Optional[str] = None):
        super().__init__(year=year, ccaa='cataluna', tipo='locales')
        self._load_cache()
        
        # Si se especifica municipio, hacer fuzzy matching UNA VEZ contra la lista de municipios
        if municipio:
            import json
            from utils.normalizer import find_municipio
            
            # Cargar todos los municipios de Catalu√±a
            with open('config/cataluna_municipios.json', 'r', encoding='utf-8') as f:
                comarcas_data = json.load(f)
            
            # Crear lista plana de todos los municipios
            todos_municipios = []
            for munis in comarcas_data.values():
                todos_municipios.extend(munis)
            
            # Buscar el mejor match
            mejor_match = find_municipio(municipio, todos_municipios, threshold=80)
            
            if mejor_match:
                self.municipio = mejor_match
                if mejor_match.lower() != municipio.lower():
                    print(f"   üîç Fuzzy match: '{municipio}' ‚Üí '{mejor_match}'")
            else:
                self.municipio = municipio
        else:
            self.municipio = None
    
    def _load_cache(self):
        """Carga URLs en cach√©"""
        import json
        import os
        
        self.cached_data = {}
        
        if os.path.exists(self.CACHE_FILE):
            with open(self.CACHE_FILE, 'r', encoding='utf-8') as f:
                cache = json.load(f)
                # Filtrar las instrucciones
                self.cached_data = {k: v for k, v in cache.items() if not k.startswith('_')}
    
    def get_source_url(self) -> str:
        """Construye la URL del XML del DOGC para el a√±o especificado"""
        year_str = str(self.year)
        
        if year_str not in self.cached_data:
            raise ValueError(
                f"No hay datos disponibles para Catalu√±a {self.year}.\n"
                f"A√±os disponibles: {list(self.cached_data.keys())}\n"
                f"Para a√±adir un nuevo a√±o, consulta las instrucciones en {self.CACHE_FILE}"
            )
        
        doc_info = self.cached_data[year_str]
        document_id = doc_info['documentId']
        version_id = doc_info['versionId']
        
        url = f"https://portaldogc.gencat.cat/utilsEADOP/AppJava/AkomaNtoso?idNumber={document_id}&idVersion={version_id}&format=xml"
        
        return url
    
    def scrape(self) -> List[Dict]:
        """Ejecuta el proceso completo de scraping con fallback a archivo local"""
        import os
        
        print(f"\n{'='*80}")
        print(f"üîç Iniciando scraping: {self.ccaa.upper()} - {self.tipo.upper()} - {self.year}")
        print(f"{'='*80}")
        
        # Intentar descargar desde URL
        try:
            url = self.get_source_url()
            content = self.download_content(url)
            festivos = self.parse_festivos(content)
            
            print(f"\n‚úÖ Scraping completado:")
            print(f"   ‚Ä¢ Festivos extra√≠dos: {len(festivos)}")
            print(f"   ‚Ä¢ Fuente: {url}")
            print(f"{'='*80}\n")
            
            return festivos
            
        except Exception as e:
            # Si falla la descarga, intentar leer desde archivo local
            local_file = f"examples/cataluna/festivos_locales_{self.year}.xml"
            
            if os.path.exists(local_file):
                print(f"\n‚ö†Ô∏è  Descarga fall√≥, usando archivo local: {local_file}")
                with open(local_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                festivos = self.parse_festivos(content)
                
                print(f"\n‚úÖ Scraping completado:")
                print(f"   ‚Ä¢ Festivos extra√≠dos: {len(festivos)}")
                print(f"   ‚Ä¢ Fuente: Archivo local")
                print(f"{'='*80}\n")
                
                return festivos
            else:
                print(f"\n‚ùå Error: {e}")
                print(f"‚ùå No existe archivo local: {local_file}")
                print(f"{'='*80}\n")
                return []
    
    def download_content(self, url: str) -> str:
        """Descarga el XML del DOGC (intentando m√∫ltiples m√©todos por problemas SSL)"""
        print(f"üì• Descargando XML: {url}")
        
        # M√©todo 1: curl (suele funcionar mejor con SSL problem√°tico)
        import subprocess
        
        try:
            result = subprocess.run(
                ['curl', '-k', '-L', url],  # -k ignora SSL, -L sigue redirects
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.returncode == 0 and len(result.stdout) > 1000:
                print(f"‚úÖ XML descargado con curl ({len(result.stdout)} caracteres)")
                return result.stdout
        except Exception as e:
            print(f"‚ö†Ô∏è  curl fall√≥: {e}")
        
        # M√©todo 2: requests con SSL verify=False
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
            }
            
            r = requests.get(url, timeout=30, verify=False, headers=headers)
            
            if r.status_code == 200:
                print(f"‚úÖ XML descargado con requests ({len(r.text)} caracteres)")
                return r.text
        except Exception as e:
            print(f"‚ö†Ô∏è  requests fall√≥: {e}")
        
        raise Exception(f"No se pudo descargar el XML con ning√∫n m√©todo")
    
    def parse_festivos(self, content: str) -> List[Dict]:
        """
        Parsea festivos desde el XML Akoma Ntoso.
        
        Estructura:
        - XML contiene HTML escapado en el campo 'period'
        - HTML tiene formato: "MUNICIPIO, DD de mes y DD de mes."
        - L√≠neas indentadas son agregados/n√∫cleos
        """
        print(f"üîç Parseando festivos locales de Catalu√±a...")
        if self.municipio:
            print(f"   üéØ Filtrando por municipio: {self.municipio}")
        
        # Parsear XML
        root = ET.fromstring(content)
        
        # Buscar el campo 'period' que contiene el HTML
        ns = {'akn': 'http://docs.oasis-open.org/legaldocml/ns/akn/3.0'}
        content_elem = root.find('.//akn:content', ns)
        
        if content_elem is None:
            raise Exception("No se encontr√≥ el elemento 'content' en el XML")
        
        html_content = content_elem.get('period', '')
        
        if not html_content:
            raise Exception("El campo 'period' est√° vac√≠o")
        
        # Decodificar HTML escapado
        html_decoded = html.unescape(html_content)
        
        # Parsear HTML con BeautifulSoup
        soup = BeautifulSoup(html_decoded, 'html.parser')
        
        # Extraer todo el texto
        texto = soup.get_text('\n')
        lineas = [l for l in texto.split('\n') if l.strip()]
        
        festivos = []
        provincia_actual = None
        municipio_principal = None
        
        for linea in lineas:
            linea_original = linea
            linea_strip = linea.strip()
            
            # Detectar provincias (en may√∫sculas solas)
            provincias = ['ALT CAMP', 'ALT EMPORD√Ä', 'ALT PENED√àS', 'ALT URGELL', 'ALTA RIBAGOR√áA', 
                         'ANOIA', 'BAGES', 'BAIX CAMP', 'BAIX EBRE', 'BAIX EMPORD√Ä', 'BAIX LLOBREGAT',
                         'BAIX PENED√àS', 'BARCELON√àS', 'BERGUED√Ä', 'CERDANYA', 'CONCA DE BARBER√Ä',
                         'GARRAF', 'GARRIGUES', 'GARROTXA', 'GIRON√àS', 'MARESME', 'MOIAN√àS',
                         'MONTSI√Å', 'NOGUERA', 'OSONA', 'PALLARS JUSS√Ä', 'PALLARS SOBIR√Ä',
                         'PLA DE L\'URGELL', 'PLA D\'URGELL', 'PRIORAT', 'RIBERA D\'EBRE',
                         'RIPOLL√àS', 'SEGARRA', 'SEGRI√Ä', 'SELVA', 'SOLSON√àS', 'TARRAGON√àS',
                         'TERRA ALTA', 'URGELL', 'VAL D\'ARAN', 'VALL√àS OCCIDENTAL', 'VALL√àS ORIENTAL']
            
            if linea_strip.upper() in provincias:
                provincia_actual = linea_strip.title()
                print(f"\nüìç {provincia_actual}:")
                continue
            
            # Buscar l√≠neas con fechas (formato: DD de mes)
            if re.search(r'\d{1,2}\s+de\s+(enero|febrero|marzo|abril|mayo|junio|julio|agosto|septiembre|octubre|noviembre|diciembre)', linea_strip, re.IGNORECASE):
                
                # Determinar si es municipio principal o agregado
                es_agregado = linea_original.startswith('    ') or linea_original.startswith('\t')
                
                if not es_agregado:
                    # Es un municipio principal
                    nombre_municipio = self._extraer_nombre_municipio(linea_strip)
                    municipio_principal = nombre_municipio
                else:
                    # Es un agregado/n√∫cleo
                    nombre_municipio = self._extraer_nombre_municipio(linea_strip)
                    # Si el municipio principal es conocido, incluirlo en el nombre
                    if municipio_principal:
                        nombre_municipio = f"{municipio_principal} - {nombre_municipio}"
                
                # Normalizar nombre
                nombre_normalizado = self._normalizar_municipio(nombre_municipio if not es_agregado else nombre_municipio.split(' - ')[-1])
                
                # Filtrar por municipio si se especific√≥
                if self.municipio:
                    municipio_busqueda = self._normalizar_municipio(self.municipio).lower()
                    municipio_encontrado = nombre_normalizado.lower()
                    
                    # Comparaci√≥n exacta
                    if municipio_busqueda != municipio_encontrado:
                        continue
                
                # Extraer fechas
                fechas_extraidas = self._extraer_fechas(linea_strip)
                
                if fechas_extraidas:
                    if not es_agregado or not self.municipio:  # Solo contar municipios principales en el log
                        print(f"   ‚Ä¢ {nombre_normalizado}: {len(fechas_extraidas)} festivos")
                    
                    for fecha_iso, fecha_texto, descripcion in fechas_extraidas:
                        festivos.append({
                            'fecha': fecha_iso,
                            'fecha_texto': fecha_texto,
                            'descripcion': descripcion or f'Festivo local de {nombre_normalizado}',
                            'tipo': 'local',
                            'ambito': nombre_normalizado,
                            'municipio': nombre_normalizado,
                            'provincia': provincia_actual,
                            'sustituible': False,
                            'year': self.year
                        })
        
        print(f"\n   ‚úÖ Festivos locales extra√≠dos: {len(festivos)}")
        
        return festivos
    
    def _extraer_nombre_municipio(self, linea: str) -> str:
        """
        Extrae el nombre del municipio de la l√≠nea.
        Formato: "MUNICIPIO, DD de mes y DD de mes."
        """
        # Separar por la primera coma
        partes = linea.split(',', 1)
        if partes:
            return partes[0].strip()
        return linea.strip()
    
    def _extraer_fechas(self, texto: str) -> List[tuple]:
        """
        Extrae fechas del formato:
        "DD de mes y DD de mes" o "DD de mes, DD de mes"
        Ignora fechas con a√±o expl√≠cito (como firmas)
        
        Returns:
            Lista de tuplas (fecha_iso, fecha_texto, descripcion)
        """
        fechas = []
        
        # Patr√≥n: DD de mes (sin a√±o, para evitar la firma "11 de diciembre de 2025")
        patron = r'(\d{1,2})\s+de\s+(enero|febrero|marzo|abril|mayo|junio|julio|agosto|septiembre|octubre|noviembre|diciembre)(?!\s+de\s+\d{4})'
        
        matches = re.findall(patron, texto, re.IGNORECASE)
        
        for dia, mes_texto in matches:
            dia = int(dia)
            fecha_iso = self._convertir_fecha(dia, mes_texto)
            
            if fecha_iso:
                fecha_texto = f"{dia} de {mes_texto}"
                fechas.append((fecha_iso, fecha_texto, None))
        
        return fechas
    
    def _convertir_fecha(self, dia: int, mes_texto: str) -> Optional[str]:
        """Convierte d√≠a y mes a formato ISO"""
        meses = {
            'enero': 1, 'febrero': 2, 'marzo': 3, 'abril': 4,
            'mayo': 5, 'junio': 6, 'julio': 7, 'agosto': 8,
            'septiembre': 9, 'octubre': 10, 'noviembre': 11, 'diciembre': 12
        }
        
        mes = meses.get(mes_texto.lower())
        if not mes:
            return None
        
        return f"{self.year}-{mes:02d}-{dia:02d}"
    
    def _normalizar_municipio(self, nombre: str) -> str:
        """Normaliza el nombre del municipio"""
        # Title case
        nombre = nombre.title()
        
        # Casos especiales catalanes
        nombre = re.sub(r'\bDe\b', 'de', nombre)
        nombre = re.sub(r'\bDel\b', 'del', nombre)
        nombre = re.sub(r'\bDels\b', 'dels', nombre)
        nombre = re.sub(r'\bDes\b', 'des', nombre)
        nombre = re.sub(r'\bDe La\b', 'de la', nombre)
        nombre = re.sub(r'\bDe Les\b', 'de les', nombre)
        nombre = re.sub(r"D'", "d'", nombre)
        nombre = re.sub(r"L'", "l'", nombre)
        nombre = re.sub(r'\bEl\b', 'el', nombre)
        nombre = re.sub(r'\bLa\b', 'la', nombre)
        nombre = re.sub(r'\bLes\b', 'les', nombre)
        nombre = re.sub(r'\bEls\b', 'els', nombre)
        
        # Art√≠culos al inicio en may√∫scula
        if nombre.lower().startswith("el "):
            nombre = "El" + nombre[2:]
        if nombre.lower().startswith("la "):
            nombre = "La" + nombre[2:]
        if nombre.lower().startswith("les "):
            nombre = "Les" + nombre[3:]
        if nombre.lower().startswith("els "):
            nombre = "Els" + nombre[3:]
        if nombre.lower().startswith("l'"):
            nombre = "L'" + nombre[2:]
        if nombre.lower().startswith("d'"):
            nombre = "D'" + nombre[2:]
        
        # Sant/Santa
        nombre = re.sub(r'\bSant\b', 'Sant', nombre)
        nombre = re.sub(r'\bSanta\b', 'Santa', nombre)
        
        return nombre


# Para testing
if __name__ == "__main__":
    import sys
    
    municipio = sys.argv[1] if len(sys.argv) > 1 else None
    year = int(sys.argv[2]) if len(sys.argv) > 2 else 2026
    
    print(f"{'='*80}")
    print(f"üß™ TEST: Catalu√±a Locales - {municipio or 'TODOS'} {year}")
    print(f"{'='*80}\n")
    
    scraper = CatalunaLocalesScraper(year=year, municipio=municipio)
    festivos = scraper.scrape()
    
    print(f"\n{'='*80}")
    print(f"üìä RESUMEN - CATALU√ëA {year}")
    print(f"{'='*80}")
    print(f"Total festivos: {len(festivos)}\n")
    
    if festivos:
        print("üìÖ Festivos:")
        for f in festivos[:10]:
            print(f"   ‚Ä¢ {f['fecha']} - {f['descripcion']}")
        
        if len(festivos) > 10:
            print(f"\n   ... y {len(festivos) - 10} m√°s")